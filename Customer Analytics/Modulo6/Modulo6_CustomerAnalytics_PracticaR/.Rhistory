filter(upos %in% c("NOUN", "ADJ")) %>%
filter(!token %in% c("zara", "gracias", "por", "favor", "vez")) %>%
select(id = doc_id, word = lemma) %>%
mutate(id = str_replace_all(id, "doc", "")) %>%
count(word, id) %>%
cast_dtm(id, word, n)
#Para completar el ejercicio deberan cargar las siguientes librerías:
# tidyverse, stringr, rtweet, readtext, tidytext, udpipe, quanteda, syuzhet, topicmodels
library(tidyverse)
library(stringr)
library(rtweet)
library(readtext)
library(tidytext)
library(udpipe)
library(quanteda)
library(syuzhet)
library(topicmodels)
#PISTA: consulta la ayuda de la función search_tweets
Tweets_Zara <- search_tweets(q="Zara", n = 18000, include_rts = FALSE, lang= "es")
View(Tweets_Zara)
#Inspecciona el dataframe
#El dataset descargado contiene 90 columnas, pero no nos interesan todas. Selecciona las columnas:
# created_at, screen_name, text, favorite_count, retweet_count, lang, status_url, name, location,
# description, followers_count, friends_count, statuses_count
Tweets_Zara_Data <- Tweets_Zara %>%
select(created_at,
screen_name,
text,
favorite_count,
retweet_count,
lang,
status_url,
name,
location,
description,
followers_count,
friends_count,
statuses_count)
View(Tweets_Zara_Data)
View(Tweets_Zara_Data)
#Convierte el texto en minúsculas. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[0]
#Convierte el texto en minúsculas. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[1]
#Convierte el texto en minúsculas. PISTA: utiliza la librería stringr
str_to_lower(Tweets_Zara_Data$text[1])
#Convierte el texto en minúsculas. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text <- str_to_lower(Tweets_Zara_Data$text)
View(Tweets_Zara_Data)
#Convierte la fecha de creación en Date
Tweets_Zara_Data$created_at[1]
#Convierte la fecha de creación en Date
Tweets_Zara_Data$created_at[1]as.Date()
#Convierte la fecha de creación en Date
as.Date(Tweets_Zara_Data$created_at[1])
View(Tweets_Zara_Data)
#Convierte la fecha de creación en Date
Tweets_Zara_Data$created_at <- as.Date(Tweets_Zara_Data$created_at)
View(Tweets_Zara_Data)
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[1]
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[2]
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[3]
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[4]
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[5]
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text[6]
str_replace_all(
Tweets_Zara_Data$text[6], # column we want to search
c("ó" = "o","í" = "i") # each string schould be matched with a replacement
)
str_replace_all(
Tweets_Zara_Data$text[6], # column we want to search
c("ó" = "o","á" = "a") # each string schould be matched with a replacement
)
#Sustituye las letras acentuadas por letras sin acentuar. PISTA: utiliza la librería stringr
Tweets_Zara_Data$text <- str_replace_all(
Tweets_Zara_Data$text,
c("á" = "a", "é" = "e", "í" = "i", "ó" = "o", "ú" = "u"))
View(Tweets_Zara_Data)
#Inspecciona de nuevo el dataset con summary, str y head.
summary(Tweets_Zara_Data)
str(Tweets_Zara_Data)
head(Tweets_Zara_Data)
#Verifica que el texto se transformó en minúsculas y que las letras con acento se sustituyeron por letras sin acentuar
Tweets_Zara_Data %>% filter(str_detect(text, "á"))
Tweets_Zara_Data %>% filter(str_detect(text, "ú"))
#¿Cuántos registros (tweets) contiene el dataset?
nrow(Tweets_Zara_Data)
View(Tweets_Zara_Data)
View(Tweets_Zara_Data)
#Añade una nueva columna al dataset que unifique el volumen total de interacciones
#La columna se debe llamar "interacciones" y se calcula como la suma de favorite_count y retweet_count para cada registro
Tweets_Zara_Data <- Tweets_Zara_Data %>%
mutate(total_interacciones = favorite_count + retweet_count)
View(Tweets_Zara_Data)
#Visualiza el número de tweets por día. ¿En qué día se crearon más tweets?
ggplot(Tweets_Zara_Data, aes(x=created_at)) + geom_histogram()
ggplot(Tweets_Zara_Data, aes(x=created_at)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")
#Visualiza el número de tweets por día. ¿En qué día se crearon más tweets?
ggplot(Tweets_Zara_Data, aes(x=created_at)) + geom_histogram()
#Calcula el número total (suma) de interacciones por día. Represéntalo gráficamente
#¿En qué día hubo más interacciones?
Tweets_Zara_Data_interactions <- Tweets_Zara_Data %>%
group_by(created_at) %>%
summarise(num_casos = n(),
sum_interactions = sum(total_interacciones))
View(Tweets_Zara_Data_interactions)
ggplot(Tweets_Zara_Data_interactions, aes(x=sum_interactions)) + geom_histogram()
ggplot(data=df, aes(x=created_at, y=sum_interactions)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=len), vjust=1.6, color="white", size=3.5)+
theme_minimal()
ggplot(data=df, aes(x=created_at, y=sum_interactions)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=len), vjust=1.6, color="white", size=3.5)+
theme_minimal()
ggplot(data=Tweets_Zara_Data_interactions, aes(x=created_at, y=sum_interactions)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=len), vjust=1.6, color="white", size=3.5)+
theme_minimal()
ggplot(data=Tweets_Zara_Data_interactions, aes(x=created_at, y=sum_interactions)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_interactions), vjust=1.6, color="white", size=3.5)+
theme_minimal()
#Visualiza el número de tweets por día. ¿En qué día se crearon más tweets?
ggplot(Tweets_Zara_Data, aes(x=created_at)) + geom_histogram() + theme_minimal()
View(Tweets_Zara_Data_interactions)
View(Tweets_Zara_Data)
View(Tweets_Zara_Data)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
summarise(num_casos = n(),
sum_followers = sum(followers_count))
View(Tweets_Zara_Data_followers)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
summarise(sum_followers = sum(followers_count))
View(Tweets_Zara_Data_followers)
ggplot(data=head(Tweets_Zara_Data_interactions, n = 10), aes(x=screen_name, y=followers_count)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_interactions), vjust=1.6, color="white", size=3.5)+
theme_minimal()
h <- head(Tweets_Zara_Data_interactions, n = 10)
ggplot(data=h, aes(x=screen_name, y=followers_count)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=followers_count), vjust=1.6, color="white", size=3.5)+
theme_minimal()
View(h)
h <- head(Tweets_Zara_Data_followers, n = 10)
ggplot(data=h, aes(x=screen_name, y=followers_count)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=followers_count), vjust=1.6, color="white", size=3.5)+
theme_minimal()
ggplot(data=h, aes(x=screen_name, y=sum_followers)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_followers), vjust=1.6, color="white", size=3.5)+
theme_minimal()
h <- head(Tweets_Zara_Data_followers, n = 10)
head(Tweets_Zara_Data_followers, n = 10)
h <- h[order(sum_followers),]
h <- head(Tweets_Zara_Data_followers, n = 10)
View(h)
h <- h[order(sum_followers),]
h <- h[order(sum_followers),]
Tweets_Zara_Data_followers <- Tweets_Zara_Data_followers[order(sum_followers),]
order(Tweets_Zara_Data_followers$sum_followers)
Tweets_Zara_Data_followers <- order(Tweets_Zara_Data_followers$sum_followers)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
summarise(sum_followers = sum(followers_count))
Tweets_Zara_Data_followers <- Tweets_Zara_Data_followers[order(Tweets_Zara_Data_followers$sum_followers),]
View(Tweets_Zara_Data_followers)
Tweets_Zara_Data_followers <- Tweets_Zara_Data_followers[order(-Tweets_Zara_Data_followers$sum_followers),]
View(Tweets_Zara_Data_followers)
ggplot(data=h, aes(x=created_at, y=sum_interactions)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_interactions), vjust=1.6, color="white", size=3.5)+
theme_minimal()
ggplot(data=h, aes(x=screen_name, y=sum_interactions)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_interactions), vjust=1.6, color="white", size=3.5)+
theme_minimal()
ggplot(data=h, aes(x=screen_name, y=sum_followers)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_followers), vjust=1.6, color="white", size=3.5)+
theme_minimal()
h <- head(Tweets_Zara_Data_followers, n = 10)
ggplot(data=h, aes(x=screen_name, y=sum_followers)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_followers), vjust=1.6, color="white", size=3.5)+
theme_minimal()
h <- head(Tweets_Zara_Data_followers, n = 5)
ggplot(data=h, aes(x=screen_name, y=sum_followers)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=sum_followers), vjust=1.6, color="white", size=3.5)+
theme_minimal()
View(h)
View(Tweets_Zara_Data_followers)
View(Tweets_Zara_Data)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
select(screen_name, followers_count)
View(Tweets_Zara_Data_followers)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
select(followers_count)
View(Tweets_Zara_Data_followers)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
summarise(followers_count=followers_count)
View(Tweets_Zara_Data_followers)
View(Tweets_Zara_Data_followers)
#¿Qué cuentas (screen_name) tienen mayor (max) número de followers? Pista, necesito utilizar la columna followers_count
Tweets_Zara_Data_followers <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
select(screen_name, followers_count)
Tweets_Zara_Data_followers <- unique(Tweets_Zara_Data_followers)
View(Tweets_Zara_Data_followers)
Tweets_Zara_Data_followers <- Tweets_Zara_Data_followers[order(-Tweets_Zara_Data_followers$sum_followers),]
Tweets_Zara_Data_followers <- Tweets_Zara_Data_followers[order(-Tweets_Zara_Data_followers$followers_count),]
h <- head(Tweets_Zara_Data_followers, n = 5)
ggplot(data=h, aes(x=screen_name, y=followers_count)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=followers_count), vjust=1.6, color="white", size=3.5)+
theme_minimal()
View(Tweets_Zara_Data)
#¿Cuál fue el tuit con más retweets? Pista, necesito utilizar la columna retweet_count
Tweets_Zara_Data_Retweets <- Tweets_Zara_Data %>%
group_by(text) %>%
select(text, retweet_count)
View(Tweets_Zara_Data_Retweets)
Tweets_Zara_Data_Retweets <- Tweets_Zara_Data_Retweets[order(-Tweets_Zara_Data_Retweets$retweet_count),]
View(Tweets_Zara_Data_Retweets)
Tweets_Zara_Data_Retweets[0]
Tweets_Zara_Data_Retweets[0][1]
Tweets_Zara_Data_Retweets[0][0]
Tweets_Zara_Data_Retweets[0,0]
head(Tweets_Zara_Data_Retweets, n = 5)
Tweets_Zara_Data_likes <- Tweets_Zara_Data_likes[order(-Tweets_Zara_Data_likes$favorite_count),]
#¿Cuál fue el tuit con más likes? Pista, necesito utilizar la columna favorite_count
Tweets_Zara_Data_likes <- Tweets_Zara_Data %>%
group_by(screen_name) %>%
select(screen_name, favorite_count)
Tweets_Zara_Data_likes <- Tweets_Zara_Data_likes[order(-Tweets_Zara_Data_likes$favorite_count),]
head(Tweets_Zara_Data_likes, n = 5)
#¿Cuál fue el tuit con más likes? Pista, necesito utilizar la columna favorite_count
Tweets_Zara_Data_likes <- Tweets_Zara_Data %>%
group_by(text) %>%
select(text, favorite_count)
Tweets_Zara_Data_likes <- Tweets_Zara_Data_likes[order(-Tweets_Zara_Data_likes$favorite_count),]
head(Tweets_Zara_Data_likes, n = 5)
View(Tweets_Zara_Data)
View(Tweets_Zara)
View(Tweets_Zara_Data)
#Utiliza la función unnest_tokens() de la librería tidytext para tokenizar el texto
#Cuenta el número de palabras y ordenálas en orden descendente según su frecuencia
#PISTA: utiliza el parámetro token= "tweets". Consulta la ayuda de la función unnest_tokens()
Tokens_Tweets_Zara <- Tweets_Zara_Data %>%
unnest_tokens(input = text, output = "palabra", token = "tweets", drop = FALSE)
View(Tokens_Tweets_Zara)
Tweets_Zara_Token <- Tweets_Zara_Data %>%
unnest_tokens(word, text, drop = FALSE, token = "tweets") %>%
count(word) %>%
arrange(desc(n))
View(Tweets_Zara_Token)
#Excluye menciones del dataframe tokenizado Tweets_Zara_Token.
#PISTA: utiliza filter() junto con str_detect() con pattern = "@[:alnum:]", consulta el script 2_Libreria_RTWEET
Menciones_Zara4 <- Tweets_Zara_Token %>%
filter(str_detect(word, pattern = "@[:alnum:]"))
View(Menciones_Zara4)
#Crea un dataframe que contenga los hashtags. PISTA: consulta el script 2_Libreria_RTWEET
Hashtags_Zara <- Tweets_Zara_Token %>%
filter(str_detect(word, pattern = "#[:alnum:]"))
View(Hashtags_Zara)
#Representamos los hashtags como un wordcloud utilizando la librería wordcloud, que no fue introducida en las sesiones prácticas
#Puedes hacer pruebas y variar los parámetros max.words, min.freq, scale, etc para observar como varía el resultado
#install.packages("wordcloud")
library(wordcloud)
#Representamos los hashtags como un wordcloud utilizando la librería wordcloud, que no fue introducida en las sesiones prácticas
#Puedes hacer pruebas y variar los parámetros max.words, min.freq, scale, etc para observar como varía el resultado
#install.packages("wordcloud")
library(RColorBrewer)
library(wordcloud)
wordcloud(
words = Hashtags_Zara$word,
freq = Hashtags_Zara$n,
max.words = 80,
min.freq = 4,
scale =c(2.8,0.75),
random.order = T,
rot.per = 0.3, random.color = T,
color = brewer.pal(4, "BrBG"))
View(Tweets_Zara_Data_interactions)
#Como el dataset es relativamente grande, en esta sección trabajaremos con una muestra.
#Seleccionamos una muestra de 500 tweets de forma aleatoria utilizando la función sample.
#Dataset_Zara_subset <- Dataset_Zara[sample(nrow(Dataset_Zara), size=500), ]
Dataset_Zara_subset <- Tweets_Zara_Data[sample(nrow(Tweets_Zara_Data), size=500), ]
View(Dataset_Zara_subset)
#Utilizamos la función get_nrc_sentiment() con el parámetro language= "spanish"
Analisis_NRC <- get_nrc_sentiment(char_v = Dataset_Zara_subset$text, language = "spanish")
#Inspecciona el resultado utilizando View()
view(Analisis_NRC)
#Unificamos el resultado y el dataframe de partida Dataset_Zara_subset, utilizando la función cbind()
Analisis_NRC_df <- cbind(Dataset_Zara_subset, Analisis_NRC)
View(Analisis_NRC_df)
View(Tweets_Zara_Data)
#Como el dataset es relativamente grande, en esta sección trabajaremos con una muestra.
#Seleccionamos una muestra de 500 tweets de forma aleatoria utilizando la función sample.
Dataset_Zara_subset <- Tweets_Zara_Data %>%
select(text)
#Como el dataset es relativamente grande, en esta sección trabajaremos con una muestra.
#Seleccionamos una muestra de 500 tweets de forma aleatoria utilizando la función sample.
Dataset_Zara_subset <- Tweets_Zara_Data %>% select(text)
Dataset_Zara_subset <- Dataset_Zara[sample(nrow(Dataset_Zara), size=500), ]
#Como el dataset es relativamente grande, en esta sección trabajaremos con una muestra.
#Seleccionamos una muestra de 500 tweets de forma aleatoria utilizando la función sample.
Dataset_Zara <- Tweets_Zara_Data %>% select(text)
Dataset_Zara_subset <- Dataset_Zara[sample(nrow(Dataset_Zara), size=500), ]
View(Dataset_Zara_subset)
#Utilizamos la función get_nrc_sentiment() con el parámetro language= "spanish"
Analisis_NRC <- get_nrc_sentiment(char_v = Dataset_Zara_subset$text, language = "spanish")
#Inspecciona el resultado utilizando View()
view(Analisis_NRC)
#Unificamos el resultado y el dataframe de partida Dataset_Zara_subset, utilizando la función cbind()
Analisis_NRC_df <- cbind(Dataset_Zara_subset, Analisis_NRC)
#Unificamos el resultado y el dataframe de partida Dataset_Zara_subset, utilizando la función cbind()
Analisis_NRC_df <- cbind(Dataset_Zara_subset, Analisis_NRC)
View(Analisis_NRC_df)
#Inspecciona de nuevo el resultado utilizando summary
# Observa los valores mínimo, máximo y medio para cada una de las 8 emociones y para las columnas negative/positive
summary(Analisis_NRC_df)
# 1) Calcula la suma total de la columna positive
positive <- sum(Analisis_NRC_df$positive)
# 2) Calcula la suma total de la coluna negative.
negative <- sum(Analisis_NRC_df$negative)
# ¿La polaridad de la conversación es positiva o negativa?. PISTA: resta el total negativo al total positivo
polaridad <- negative - positive
polaridad
#Finalmente podemos analizar el porcentaje de cada emoción en la conversación
#Solución: utilizamos la función prop.table y colSums para obtener el porcentaje de cada emoción
# La función prop.table divide el valor de cada celda entre la suma total de filas y columnas (% de la celda)
# La función colSums() suma el valor de todas las celdas de cada columna (% de la columna)
Analisis_NRC_emotions <- colSums(prop.table(Analisis_NRC_df[c("anger", "anticipation", "disgust", "fear",
"joy", "sadness", "surprise", "trust")]))
sort(Analisis_NRC_emotions*100, decreasing= TRUE)
#Inspeccionamos ejemplos
angry_items <- which(Analisis_NRC_df$anger > 0)
Analisis_NRC_df[angry_items, "text"]
joy_items <- which(Analisis_NRC_df$joy > 0)
Analisis_NRC_df[joy_items, "text"]
#Descargamos y cargamos el modelo para español.
ud_model <- udpipe_download_model(language = "spanish")
#ud_model <- udpipe_load_model(ud_model$file) #Esta línea no se ejecuta correctamente si existe más de un modelo en el directorio de nuestro ordenador
ud_model <- udpipe_load_model(file= "spanish-gsd-ud-2.4-190531.udpipe") #Al especificar el nombre del modelo a cargar, aseguramos que sí cargue el modelo correctamente
#ud_model <- udpipe_load_model(ud_model$file) #Esta línea no se ejecuta correctamente si existe más de un modelo en el directorio de nuestro ordenador
ud_model <- udpipe_load_model(file= "spanish-gsd-ud-2.5-191206.udpipe") #Al especificar el nombre del modelo a cargar, aseguramos que sí cargue el modelo correctamente
#Lo aplicamos sobre la columna del texto de tuits, generando 14 variables
Dataset_Zara_ud <- udpipe_annotate(ud_model,
x = Dataset_Zara$text,
parallel.cores = 2)
View(Dataset_Zara_ud)
#Convertimos en data frame. Inspecciona el resultado, revisa las variables generadas por la función udpipe_annotate()
Dataset_Zara_ud <- as.data.frame(Dataset_Zara_ud)
View(Dataset_Zara_ud)
#Observa que los signos de puntuación no han sido eliminados
#Utilizando la columna "token", elimina los signos de puntuación y las menciones
#PISTA: para eliminar signos de puntuación utiliza el patrón "[:punct:]". Revisa la cheatsheet de stringr vista en clase.
Dataset_Zara_ud_filter <- Dataset_Zara_ud %>%
filter(str_detect(token, pattern = "[:punct:]"))
View(Dataset_Zara_ud_filter)
#Observa que los signos de puntuación no han sido eliminados
#Utilizando la columna "token", elimina los signos de puntuación y las menciones
#PISTA: para eliminar signos de puntuación utiliza el patrón "[:punct:]". Revisa la cheatsheet de stringr vista en clase.
Dataset_Zara_ud_filter <- Dataset_Zara_ud %>%
filter(!str_detect(token, pattern = "[:punct:]"))
View(Dataset_Zara)
View(Dataset_Zara_ud_filter)
#Observa que los signos de puntuación no han sido eliminados
#Utilizando la columna "token", elimina los signos de puntuación y las menciones
#PISTA: para eliminar signos de puntuación utiliza el patrón "[:punct:]". Revisa la cheatsheet de stringr vista en clase.
Dataset_Zara_ud <- Dataset_Zara_ud %>%
filter(!str_detect(token, pattern = "[:punct:]"))
#Analicemos los adjetivos
Adjetivos_Zara <- Dataset_Zara_ud %>%
filter(upos == "ADJ") %>%
count(token) %>%
arrange(desc(n))
wordcloud(
words = Adjetivos_Zara$token,
freq = Adjetivos_Zara$n,
max.words = 80,
min.freq = 5,
scale =c(4.8,0.4),
random.order = T,
rot.per = 0.3, random.color = T,
color = brewer.pal(4, "BrBG"))
#Analiza los verbos y representa un wordcloud como hemos hecho en el caso de los adjetivos
#PISTA: utiliza la condición de filtrado upos == "VERB"
Verbos_Zara <- Dataset_Zara_ud %>%
filter(upos == "VERB") %>%
count(token) %>%
arrange(desc(n))
wordcloud(
words = Verbos_Zara$token,
freq = Verbos_Zara$n,
max.words = 80,
min.freq = 5,
scale =c(4.8,0.4),
random.order = T,
rot.per = 0.3, random.color = T,
color = brewer.pal(4, "BrBG"))
#Leemos el resultados de los pasos anteriores
Dataset_Zara_ud <- read.csv("datasets/Dataset_Zara_ud.csv")
#Nota: la libería topicmodels está construida utilizando objetos del paquete tm. Para poder ejecutar funciones
#de este paquete, debemos transformar en Document Term Matrix (dtm) utilizando la función cast_dtm()
Modelo_Zara <- Dataset_Zara_ud %>%
filter(upos %in% c("NOUN", "ADJ")) %>%
filter(!token %in% c("zara", "gracias", "por", "favor", "vez")) %>%
select(id = doc_id, word = lemma) %>%
mutate(id = str_replace_all(id, "doc", "")) %>%
count(word, id) %>%
cast_dtm(id, word, n)
#Generamos varios modelos, variando el número de temas definido en cada modelo (parámetro k)
#Utilizamos la función LDA() del paquete topicmodels
set.seed(1234)
Modelo_Zara_LDA <- LDA(Modelo_Zara, k = 3, control = list(seed = 1234))
Modelo_Zara_LDA2 <- LDA(Modelo_Zara, k = 5, control = list(seed = 1234))
Modelo_Zara_LDA3 <- LDA(Modelo_Zara, k = 8, control = list(seed = 1234))
#Transformamos en formato tidy (tibble data.frame) utilizando la función tidy()
Zara_topics <- tidy(Modelo_Zara_LDA, matrix = "beta")
Zara_topics2 <- tidy(Modelo_Zara_LDA2, matrix = "beta")
Zara_topics3 <- tidy(Modelo_Zara_LDA3, matrix = "beta")
View(Modelo_Zara_LDA)
View(Zara_topics)
View(Zara_topics2)
View(Zara_topics3)
View(Zara_topics2)
#Seleccionamos los top terms de cada modelo y los visualizamos
## Modelo k=3
Zara_top_terms <- Zara_topics %>%
group_by(topic) %>%
top_n(20, beta) %>%
ungroup() %>%
arrange(topic, -beta)
Zara_top_terms_facet <- Zara_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
View(Zara_top_terms_facet)
View(Zara_top_terms)
## Modelo k=5
Zara_top_terms2 <- Zara_topics2 %>%
group_by(topic) %>%
top_n(20, beta) %>%
ungroup() %>%
arrange(topic, -beta)
Zara_top_terms_facet2 <- Zara_top_terms2 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
## Modelo k=8
Zara_top_terms3 <- Zara_topics3 %>%
group_by(topic) %>%
top_n(20, beta) %>%
ungroup() %>%
arrange(topic, -beta)
Zara_top_terms_facet3 <- Zara_top_terms3 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
theme(axis.text=element_text(size=7)) +
scale_x_reordered() #reorder_within y scale_x_reordered permiten ordenar en cada facet (tema)
View(Zara_top_terms2)
View(Zara_top_terms_facet2)
View(Zara_top_terms_facet2)
#Finalmente, utilizando un wordcloud visualizamos las palabras más relevantes por tópico.
#Por ejemplo, para el tópico número 2
Zara_wordcloud <- Zara_topics2 %>%
filter(topic == "2") %>%
arrange(topic, -beta) %>%
mutate(beta = beta * 1000)
wordcloud(
words = Zara_wordcloud$term,
freq = Zara_wordcloud$beta,
max.words = 40,
min.freq = 5,
scale =c(4.5,0.2),
random.order = F,
rot.per = 0.1, random.color = T,
color = brewer.pal(4, "BrBG"))
save.image(file='myEnvironment.RData')
