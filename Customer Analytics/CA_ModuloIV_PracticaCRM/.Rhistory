title = 'Frecuencia de Serv_CSAT por tipo de queja') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
theme(legend.title = element_text(size = 7),
legend.text = element_text(size = 7)) +
theme(axis.text=element_text(size=7),
axis.title=element_text(size=10,face="bold"))
#*    Generamos un grafico mezclando ambas variables y asi visualizar las CSAT para cada problema tecnico
ggplot(data = DF_CRM, aes(x = Prod_CSAT, y = Serv_CSAT)) +
geom_point(aes(color = complaint_reason)) +
labs(title = 'Distribucion de Prod_CSAT y Serv_CSAT por tipo de problema t?cnico') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.title = element_text(color = 'navyblue', size = 12),
legend.text = element_text(size = 10)) +
theme(legend.background = element_rect(fill = "darkgray")) +
scale_x_continuous(limits = c(0,100), breaks = seq(0,100,10)) +
scale_y_continuous(limits = c(0,100), breaks = seq(0,100,10))
#*    Comprobamos la tipologia de cada una de nuestras variables
str(DF_CRM)
#*    Nos guardamos en un objeto todas las columnas de caracter numero, las cuales podemos trabajar la correlacion tipo
datos_numericos <- DF_CRM[,2:7]
View(datos_numericos)
#*    Creamos una Tabla con las correlaciones entre todos los datos de las columnas creadas
Tabla_correlaciones <- round(cor(datos_numericos,use = 'complete.obs'), digits = 2); Tabla_correlaciones
View(Tabla_correlaciones)
#*    Generamos un grafico para visualziar el tipo de correlacion entre las variables, ademas de visualizarlo anteriormente en una tabla
corrplot(cor(datos_numericos,use = 'complete.obs'),
type="upper",
order = 'hclust',
tl.col="black",
addCoef.col = 'black',
tl.srt=60)
library (tidyverse)
library(corrplot)
library(psych)
library(dplyr)
library(DescTools)
#*   Caargamos el dataset y eliminamos la primera columna
CRM <- read.csv('data_CRM.csv', header = T) %>%
select(-1)
#*   Sacamos descriptivos sobre las tablas
summary(CRM)
describe(CRM)
head(CRM)
#*   Estudiamos la variable 'create_date' para ver la frecuencia de quejas por dia durante nuestro periodo
table(CRM$create_date)
#*   Genero una tabla que agrupe todas las fechas registradas junto al total de quejas recibidas por dia
Distribucion_Quejas_Dia <- CRM[,c(4,8)]
Distribucion_Quejas_Dia$Queja <- 1
Distribucion_Quejas_Dia <- Distribucion_Quejas_Dia %>%
group_by(create_date) %>%
summarise(sum(Queja))
#*   Convertimos la fecha al forma 'date'
dias <- as.Date(Distribucion_Quejas_Dia$create_date)
#*   Graficamos la dsitrbucion del total de quejas por dia durante los meses de Enero - Abril
ggplot(Distribucion_Quejas_Dia, aes(x = dias, y = `sum(Queja)`)) +
geom_line(group = 1) +
labs(title = 'Numero de quejas distribuidas por dias',
y = 'Numero de Quejas',
x = 'Distribucion de Dias') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
scale_y_continuous(limits = c(80,140), breaks = seq(80,140,10)) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(color = "#FC4E07", fill = "#FC4E07", method = "loess")
DF_CRM <- data.frame(CRM %>%
group_by(complaint_reason) %>%
summarise(num_casos = length(complaint_reason),
pend_calls = length(pending_call[pending_call == "y"]),
avg_time_to_resolution = mean(time_to_resolution_min),
n_replacements = length(need_replace[need_replace == TRUE]),
Prod_CSAT = (length(ProdCSAT[!is.na(ProdCSAT) & ProdCSAT >= 4])/length(ProdCSAT[!is.na(ProdCSAT)]))*100,
Serv_CSAT = (length(ServCSAT[!is.na(ServCSAT) & ServCSAT >= 4])/length(ServCSAT[!is.na(ServCSAT)]))*100))
#*    Factorizamos nuestra variable 'Complaint_Reason' para poder graficar sobre ella con mas facilidad
complaint_reason <- as.factor(DF_CRM$complaint_reason)
#*    Generamos un grafico para visualizar de forma individual la frecuencia de 'Prod_CSAT' por quejas realizadas
ggplot(data = DF_CRM, aes(x = complaint_reason, y = Prod_CSAT, color = complaint_reason)) +
geom_point() +
labs( x = 'Complaint Reason',
y = 'Prod_CSAT',
title = 'Frecuencia de Prod_CSAT por tipo de queja') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
theme(legend.title = element_text(size = 7),
legend.text = element_text(size = 7)) +
theme(axis.text=element_text(size=7),
axis.title=element_text(size=10,face="bold"))
#*    Generamos un grafico para visualizar de forma individual la frecuencia de 'Serv_CSAT' por quejas realizadas
ggplot(data = DF_CRM, aes(x = complaint_reason, y = Serv_CSAT, color = complaint_reason)) +
geom_point() +
labs( x = 'Complaint Reason',
y = 'Serv_CSAT',
title = 'Frecuencia de Serv_CSAT por tipo de queja') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
theme(legend.title = element_text(size = 7),
legend.text = element_text(size = 7)) +
theme(axis.text=element_text(size=7),
axis.title=element_text(size=10,face="bold"))
#*    Generamos un grafico mezclando ambas variables y asi visualizar las CSAT para cada problema tecnico
ggplot(data = DF_CRM, aes(x = Prod_CSAT, y = Serv_CSAT)) +
geom_point(aes(color = complaint_reason)) +
labs(title = 'Distribucion de Prod_CSAT y Serv_CSAT por tipo de problema t?cnico') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.title = element_text(color = 'navyblue', size = 12),
legend.text = element_text(size = 10)) +
theme(legend.background = element_rect(fill = "darkgray")) +
scale_x_continuous(limits = c(0,100), breaks = seq(0,100,10)) +
scale_y_continuous(limits = c(0,100), breaks = seq(0,100,10))
#PASO 1
#Cargamos el dataset "data_CRM.csv" eliminando columna 1 que es innecesaria
data_CRM <- read.csv('data_CRM.csv')
data_CRM$X <- NULL
#Inspecciones en dataset con summary, describe y head para comprender la información que contiene, entender missing values en las columnas
summary(data_CRM)
describeData(data_CRM,head=4,tail=4)
#Realicen un plot para entender la distribución de las quejas a lo largo del período,
#selecciondo el tipo de gráfico más óptimo para representar la data
data_CRM$create_date <- as.Date(data_CRM$create_date, "%Y-%m-%d")
ggplot(data_CRM, aes(x=create_date)) + geom_histogram()
View(data_CRM)
complains_by_date <- data_CRM %>%
group_by(create_date) %>%
summarise(num_casos = n())
View(complains_by_date)
complains_by_date <- data_CRM %>%
group_by(create_date) %>%
summarise(total = n())
View(complains_by_date)
ggplot(data_CRM, aes(x = create_date, y = total)) +
geom_line(group = 1) +
labs(title = 'Numero de quejas distribuidas por dias',
y = 'Numero de Quejas',
x = 'Distribucion de Dias') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
scale_y_continuous(limits = c(80,140), breaks = seq(80,140,10)) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(color = "#FC4E07", fill = "#FC4E07", method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
labs(title = 'Numero de quejas distribuidas por dias',
y = 'Numero de Quejas',
x = 'Distribucion de Dias') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
scale_y_continuous(limits = c(80,140), breaks = seq(80,140,10)) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(color = "#FC4E07", fill = "#FC4E07", method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
labs(title = 'Numero de quejas distribuidas por dias',
y = 'Numero de Quejas',
x = 'Distribucion de Dias') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
scale_y_continuous(limits = c(80,140), breaks = seq(80,140,10)) +
theme(axis.text.x = element_text(angle=45, hjust = 1))
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
scale_y_continuous(limits = c(80,140), breaks = seq(80,140,10)) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(color = "#FC4E07", fill = "#FC4E07", method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(color = "#FC4E07", fill = "#FC4E07", method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
theme(axis.text.x = element_text(angle=45, hjust = 1)) +
stat_smooth(method = "loess")
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
stat_smooth(method = "loess")
#PASO 2
#El dataset presenta todos los casos de los usuarios que han contactado con Customer Support en el período enero-abril 2020
#Pero nos interesa hacer el análisis sobre complaint_reason, por lo cual es necesario crear un nuevo dataset,
#agrupar los datos por complaint_reason y realizar las siguientes operaciones para las columnas relevantes:
#generar una columna que cuente la cantidad de llamadas para cada tipo de complaint_reason llamada "num_casos"
#generar una columna que cuente la cantidad de llamadas pendientes para cada tipo de complaint_reason contando la cantidad de "y" llamada pend_calls
#calcular el promedio de time_to_resolution_min para cada tipo de complaint_reason en una columna nueva llamada avg_time_to_resolution
#generar una columna que cuente la cantidad de need_replace para cada tipo de complaint_reason contando la cantidad de "TRUE" llamada n_replacements
#generar una nueva columna que calcule el Prod_CSAT para cada tipo de complaint_reason en una columna nueva llamada Prod_CSAT
#generar una nueva columna que calcule el Serv_CSAT para cada tipo de complaint_reason en una columna nueva llamada Serv_CSAT
complaint_reason_group <- data_CRM %>%
group_by(case_record_type, complaint_reason) %>%
summarise(num_casos = n(),
pend_calls = sum(pending_call == 'y'),
avg_time_to_resolution = mean(time_to_resolution_min),
n_replacements = sum(need_replace == TRUE),
Prod_CSAT = length(which(na.omit(ProdCSAT) >= 4))/length(na.omit(ProdCSAT)),
Serv_CSAT = (length(which(na.omit(ServCSAT) >= 4))/length(na.omit(ServCSAT))*100))
#De esta forma el dataset nuevo debe contener las siguientes columnas: complaint_reason, num_casos, pend_calls,
#avg_time_to_resolution, n_replacements, Prod_CSAT, Serv_CSAT
complaint_reason_data <- complaint_reason_group %>%
select(complaint_reason,
num_casos,
pend_calls,
avg_time_to_resolution,
n_replacements,
Prod_CSAT,
Serv_CSAT)
complaint_reason <- as.factor(complaint_reason_data$complaint_reason)
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Prod_CSAT, fill=complaint_reason)) +
geom_bar(stat="identity", position=position_dodge()) +
theme_minimal()
#*    Generamos un grafico para visualizar de forma individual la frecuencia de 'Prod_CSAT' por quejas realizadas
ggplot(data = DF_CRM, aes(x = complaint_reason, y = Prod_CSAT, color = complaint_reason)) +
geom_point() +
labs( x = 'Complaint Reason',
y = 'Prod_CSAT',
title = 'Frecuencia de Prod_CSAT por tipo de queja') +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
theme(legend.title = element_text(size = 7),
legend.text = element_text(size = 7)) +
theme(axis.text=element_text(size=7),
axis.title=element_text(size=10,face="bold"))
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Prod_CSAT, fill=complaint_reason)) +
geom_bar() +
theme(plot.title = element_text(hjust=0.5)) +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90)) +
theme(legend.title = element_text(size = 7),
legend.text = element_text(size = 7)) +
theme(axis.text=element_text(size=7),
axis.title=element_text(size=10,face="bold"))
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Prod_CSAT, fill=complaint_reason)) +
geom_bar() +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90))
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Prod_CSAT, fill=complaint_reason)) +
geom_bar(stat="identity") +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90))
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Serv_CSAT, fill=complaint_reason)) +
geom_bar(stat="identity") +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90))
View(complaint_reason_data)
#De esta forma el dataset nuevo debe contener las siguientes columnas: complaint_reason, num_casos, pend_calls,
#avg_time_to_resolution, n_replacements, Prod_CSAT, Serv_CSAT
complaint_reason_data <- complaint_reason_group %>%
select(complaint_reason,
num_casos,
pend_calls,
avg_time_to_resolution,
n_replacements,
Prod_CSAT,
Serv_CSAT)
View(complaint_reason_data)
#PASO 2
#El dataset presenta todos los casos de los usuarios que han contactado con Customer Support en el período enero-abril 2020
#Pero nos interesa hacer el análisis sobre complaint_reason, por lo cual es necesario crear un nuevo dataset,
#agrupar los datos por complaint_reason y realizar las siguientes operaciones para las columnas relevantes:
#generar una columna que cuente la cantidad de llamadas para cada tipo de complaint_reason llamada "num_casos"
#generar una columna que cuente la cantidad de llamadas pendientes para cada tipo de complaint_reason contando la cantidad de "y" llamada pend_calls
#calcular el promedio de time_to_resolution_min para cada tipo de complaint_reason en una columna nueva llamada avg_time_to_resolution
#generar una columna que cuente la cantidad de need_replace para cada tipo de complaint_reason contando la cantidad de "TRUE" llamada n_replacements
#generar una nueva columna que calcule el Prod_CSAT para cada tipo de complaint_reason en una columna nueva llamada Prod_CSAT
#generar una nueva columna que calcule el Serv_CSAT para cada tipo de complaint_reason en una columna nueva llamada Serv_CSAT
complaint_reason_group <- data_CRM %>%
group_by(complaint_reason) %>%
summarise(num_casos = n(),
pend_calls = sum(pending_call == 'y'),
avg_time_to_resolution = mean(time_to_resolution_min),
n_replacements = sum(need_replace == TRUE),
Prod_CSAT = length(which(na.omit(ProdCSAT) >= 4))/length(na.omit(ProdCSAT)),
Serv_CSAT = (length(which(na.omit(ServCSAT) >= 4))/length(na.omit(ServCSAT))*100))
#De esta forma el dataset nuevo debe contener las siguientes columnas: complaint_reason, num_casos, pend_calls,
#avg_time_to_resolution, n_replacements, Prod_CSAT, Serv_CSAT
complaint_reason_data <- complaint_reason_group %>%
select(complaint_reason,
num_casos,
pend_calls,
avg_time_to_resolution,
n_replacements,
Prod_CSAT,
Serv_CSAT)
View(complaint_reason_group)
View(complaint_reason_data)
#PASO 4
#Realizar una correlación entre las variables numéricas y analizar si existen correlaciones fuertes entre
#alguna de las variables presentadas.
#las funciones de correlación poseen un argumento llamado use que permite excluir los NA para que el computo sea
#posible. Para ello incluyan como argumento use = "complete.obs" ya que por default es use = "everything"
#¿La columna de Serv_CSAT muestra correlaciones con alguna otra columna?
complaint_reason_data_cor <- complaint_reason_data[,2:7]
View(complaint_reason_data_cor)
M <- cor(complaint_reason_data_cor)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=FALSE)
M <- cor(complaint_reason_data_cor, use = 'complete.obs')
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag=FALSE)
#Inspeccionen la funcion cor.test para entender su funcionamiento y apliquenla sobre aquellas correlaciones
#que ustedes opinaron anteriormente que tienen correlación con la columna de Serv_CSAT para verificar si su hipotesis es correcta
#IMPORTANTE: pueden explorar los diferentes métodos, pero el que utilizamos de forma genérica es pearson
##a su vez es importante que comprendan y utilicen el argumento exact con lógica FALSE
cor.test(data_cor$avg_time_to_resolution, data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
#Inspeccionen la funcion cor.test para entender su funcionamiento y apliquenla sobre aquellas correlaciones
#que ustedes opinaron anteriormente que tienen correlación con la columna de Serv_CSAT para verificar si su hipotesis es correcta
#IMPORTANTE: pueden explorar los diferentes métodos, pero el que utilizamos de forma genérica es pearson
##a su vez es importante que comprendan y utilicen el argumento exact con lógica FALSE
cor.test(complaint_reason_data_cor$avg_time_to_resolution, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
cor.test(complaint_reason_data_cor$ProdCSAT, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
cor.test(complaint_reason_data_cor$Prod_CSAT, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
corrplot.mixed(M)
corrplot.mixed(M, lower.col = "black", number.cex = .7)
#*    Graficamos con la funcion corrplot.mixed
corrplot.mixed(Tabla_correlaciones,
tl.pos = "lt",
diag = "l",
tl.col="black")
#*    Repetimos el proceso utilizado anteriormente para poder representar los datos de correlacion mediante la funcion corrplot.mixed()
datos_numericos <- DF_CRM[,2:7]
Tabla_correlaciones <- round(cor(datos_numericos,use = 'complete.obs'), digits = 2); Tabla_correlaciones
#*    Graficamos con la funcion corrplot.mixed
corrplot.mixed(Tabla_correlaciones,
tl.pos = "lt",
diag = "l",
tl.col="black")
corrplot.mixed(M,
tl.pos = "lt",
diag = "l",
tl.col="black")
corrplot.mixed(M,
tl.pos = "lt",
diag = "l",
tl.col="black")
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black",
tl.col="black", tl.srt=45,
diag=FALSE)
#*     La correlacion entre el Serv_CSAT y Prod_CSAT es positiva y alta. Por lo que existe relacion a la hora de conceder una
#*     valoracion por parte de los consumidores hacia el producto, asi como hacia el servicio.
#*     Al igual que en el caso anterior, el p-valor esta por debajo del 0.05. Por lo que rechazamos la Hipotesis Nula
#*     y podemos confirmar que existe correlacion entre las variables.
corrplot.mixed(M,
tl.pos = "lt",
diag = "l",
tl.col="black")
#*     La correlacion entre ambas variables es positiva y la podriamos considerar alta al tener un 0.8133575 de correlacion.
#*     Por lo que podriamos concluir que el tiempo de resolucion empleado en la llamada tiene incidencia en la valoracion
#*     que el consumidor da sobre el producto
#*     Observamos un p-valor bajo, por lo que rechazamos la Hipotesis Nula. La H0 implica que no existe correlacion, por lo
#*     que con el test de Pearson podemos confirmar que si existe relacion entre las variables.
cor.test(DF_CRM$Serv_CSAT, DF_CRM$Prod_CSAT, method = "pearson")
#*     Repetimos el proceso elaborado anteriormente para la variable Serv_CSAT, pero ahora para la variable Prod_CSAT
cor.test(complaint_reason_data_cor$avg_time_to_resolution, complaint_reason_data_cor$Prod_CSAT, method = "pearson", exact = FALSE)
#*     La correlacion entre ambas variables es positiva y la podriamos considerar alta al tener un 0.8133575 de correlacion.
#*     Por lo que podriamos concluir que el tiempo de resolucion empleado en la llamada tiene incidencia en la valoracion
#*     que el consumidor da sobre el producto
#*     Observamos un p-valor bajo, por lo que rechazamos la Hipotesis Nula. La H0 implica que no existe correlacion, por lo
#*     que con el test de Pearson podemos confirmar que si existe relacion entre las variables.
cor.test(complaint_reason_data_cor$Prod_CSAT, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
#Inspeccionen la funcion cor.test para entender su funcionamiento y apliquenla sobre aquellas correlaciones
#que ustedes opinaron anteriormente que tienen correlación con la columna de Serv_CSAT para verificar si su hipotesis es correcta
#IMPORTANTE: pueden explorar los diferentes métodos, pero el que utilizamos de forma genérica es pearson
##a su vez es importante que comprendan y utilicen el argumento exact con lógica FALSE
# RESPUESTA:
#     - Aplicando el test de correlacion de Pearson entre avg_time_to_resolution y Serv_CSATServ_CSAT se puede ver
#       que el coeficiente de correlacion es de 0.7456617. Lo que indica una correlacion positiva y una relacion
#       entre el promedio de tiempo de resolucion y la valoracion otorgada al servicio por el cliente.
#     - Aplicando el mismo test para Prod_CSAT y Serv_CSAT se puede ver que el coeficiente de correlacion es de
#       0.8294235. Esto indica una relacion significativa entre estas dos variables como se explico anteriormente.
cor.test(complaint_reason_data_cor$avg_time_to_resolution, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
cor.test(complaint_reason_data_cor$Prod_CSAT, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
#MÓDULO IV - SATISFACCIÓN DEL CONSUMIDOR
#En este ejercicio estaremos trabajando con data típica que uno puede extraer del modulo de Support Service
#de un CRM sobre los problemas que se reportan con el producto o servicio
#Y contiene una encuesta de satisfaccion tanto para el producto como para el servicio brindado por el equipo de custome support
# AUTOR: Saulo Valdivia Valdivia
#Para completar el ejercicio deberan cargar las siguientes librerias: tidyverse, corrplot, psych
library(tidyverse)
library(corrplot)
library(psych)
#PISTA: Las librerias de corrplot y psych fueron utilizadas en el ejercicio de Percepcion de Marca.
#Pueden revisar ese script como referencia para esta tarea
#PASO 1
#Cargamos el dataset "data_CRM.csv" eliminando columna 1 que es innecesaria
data_CRM <- read.csv('data_CRM.csv')
data_CRM$X <- NULL
#Inspecciones en dataset con summary, describe y head para comprender la información que contiene, entender missing values en las columnas
summary(data_CRM)
describeData(data_CRM,head=4,tail=4)
#Realicen un plot para entender la distribución de las quejas a lo largo del período,
#selecciondo el tipo de gráfico más óptimo para representar la data
data_CRM$create_date <- as.Date(data_CRM$create_date, "%Y-%m-%d")
complains_by_date <- data_CRM %>%
group_by(create_date) %>%
summarise(total = n())
ggplot(complains_by_date, aes(x = create_date, y = total)) +
geom_line(group = 1) +
stat_smooth(method = "loess")
#PASO 2
#El dataset presenta todos los casos de los usuarios que han contactado con Customer Support en el período enero-abril 2020
#Pero nos interesa hacer el análisis sobre complaint_reason, por lo cual es necesario crear un nuevo dataset,
#agrupar los datos por complaint_reason y realizar las siguientes operaciones para las columnas relevantes:
#generar una columna que cuente la cantidad de llamadas para cada tipo de complaint_reason llamada "num_casos"
#generar una columna que cuente la cantidad de llamadas pendientes para cada tipo de complaint_reason contando la cantidad de "y" llamada pend_calls
#calcular el promedio de time_to_resolution_min para cada tipo de complaint_reason en una columna nueva llamada avg_time_to_resolution
#generar una columna que cuente la cantidad de need_replace para cada tipo de complaint_reason contando la cantidad de "TRUE" llamada n_replacements
#generar una nueva columna que calcule el Prod_CSAT para cada tipo de complaint_reason en una columna nueva llamada Prod_CSAT
#generar una nueva columna que calcule el Serv_CSAT para cada tipo de complaint_reason en una columna nueva llamada Serv_CSAT
complaint_reason_group <- data_CRM %>%
group_by(complaint_reason) %>%
summarise(num_casos = n(),
pend_calls = sum(pending_call == 'y'),
avg_time_to_resolution = mean(time_to_resolution_min),
n_replacements = sum(need_replace == TRUE),
Prod_CSAT = length(which(na.omit(ProdCSAT) >= 4))/length(na.omit(ProdCSAT)),
Serv_CSAT = (length(which(na.omit(ServCSAT) >= 4))/length(na.omit(ServCSAT))*100))
#De esta forma el dataset nuevo debe contener las siguientes columnas: complaint_reason, num_casos, pend_calls,
#avg_time_to_resolution, n_replacements, Prod_CSAT, Serv_CSAT
complaint_reason_data <- complaint_reason_group %>%
select(complaint_reason,
num_casos,
pend_calls,
avg_time_to_resolution,
n_replacements,
Prod_CSAT,
Serv_CSAT)
#PASO 3
#Seleccionar un plot idoneo para poder realizar una comparativa de C-SATs para cada problema técnico
#Justificar la selección de dicho plot brevemente
complaint_reason <- as.factor(complaint_reason_data$complaint_reason)
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Prod_CSAT, fill=complaint_reason)) +
geom_bar(stat="identity") +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90))
ggplot(data=complaint_reason_data, aes(x=complaint_reason, y=Serv_CSAT, fill=complaint_reason)) +
geom_bar(stat="identity") +
theme(legend.position='bottom',axis.text.x = element_text(angle = 90))
#PASO 4
#Realizar una correlación entre las variables numéricas y analizar si existen correlaciones fuertes entre
#alguna de las variables presentadas.
#las funciones de correlación poseen un argumento llamado use que permite excluir los NA para que el computo sea
#posible. Para ello incluyan como argumento use = "complete.obs" ya que por default es use = "everything"
#¿La columna de Serv_CSAT muestra correlaciones con alguna otra columna?
# RESPUESTA:
# El grafico de correlacion muestra una muy elevada correlacion entre num_casos y pend_calls. Esto implica
# una relacion directa entre el numero de casos y las llamadas pendientes.
# Otras correlaciones importantes se pueden apreciar entre:
#   avg_time_to_resolution y Prod_CSAT/Serv_CSAT. Que indica que existe una relacion elevada
#   entre el tiempo de resolucion y el puntaje del cliente al momento de evaluar la experiencia.
#   - Promedio de resolucion (avg_time_to_resolution) y Prod_CSAT con una correlacion de 0.81
#   - Promedio de resolucion (avg_time_to_resolution) y Serv_CSAT con una correlacion de 0.75
# Finalmente. La correlacion entre Prod_CSAT y Serv_CSAT es tambien elevada (0.83) lo que indica
# que el puntaje asociado al producto tiene incidencia al puntaje asignado al Servicio otorgado al cliente.
complaint_reason_data_cor <- complaint_reason_data[,2:7]
M <- cor(complaint_reason_data_cor, use = 'complete.obs')
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black",
tl.col="black", tl.srt=45,
diag=FALSE)
#Inspeccionen la funcion cor.test para entender su funcionamiento y apliquenla sobre aquellas correlaciones
#que ustedes opinaron anteriormente que tienen correlación con la columna de Serv_CSAT para verificar si su hipotesis es correcta
#IMPORTANTE: pueden explorar los diferentes métodos, pero el que utilizamos de forma genérica es pearson
##a su vez es importante que comprendan y utilicen el argumento exact con lógica FALSE
# RESPUESTA:
#     - Aplicando el test de correlacion de Pearson entre avg_time_to_resolution y Serv_CSATServ_CSAT se puede ver
#       que el coeficiente de correlacion es de 0.7456617 y el p-value es muy pequeño. Lo que indica una correlacion positiva
#       y una relacion entre el promedio de tiempo de resolucion y la valoracion otorgada al servicio por el cliente.
#     - Aplicando el mismo test para Prod_CSAT y Serv_CSAT se puede ver que el coeficiente de correlacion es de
#       0.8294235. Esto indica una relacion significativa entre estas dos variables como se explico anteriormente.
cor.test(complaint_reason_data_cor$avg_time_to_resolution, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
cor.test(complaint_reason_data_cor$Prod_CSAT, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
#Por último utilicen la función corrplot.mixed() para realizar el plot de todas las correlaciones juntas
#Intenten utilizar algunas de las opciones que presenta para embellecer el gráfico (colores, formas, tamaños, etc)
#La forma de aplicación sería corrplot.mixed(corr = (correlacion que quieren hacer con sus argumentos incluido use = "complete.obs"))
#y el resto de argumentos que quieran incluir
corrplot.mixed(M,
tl.pos = "lt",
diag = "l",
tl.col="black")
#PASO 5
#Repetir el paso 4 pero enfocando el analisis en la columna Prod_CSAT en vez de Serv_CSAT: realicen hipotesis sobre correlaciones,
#apliquen cor.test para validarlas y corrplot.mixed() para representarlo.
# RESPUESTA: Realizamos las graficas de correlacion y los tests anteriores para Prod_CSAT.
# Se puede apreciar los siguiente:
#     - Promedio de resolucion (avg_time_to_resolution) y Prod_CSAT con una correlacion de 0.8133575. Lo que indica
#       una correlacion positiva y una relacion entre el promedio de tiempo de resolucion y la valoracion otorgada al servicio por el cliente.
#     - La correlacion entre Prod_CSAT y Serv_CSAT es tambien elevada (0.8294235) lo que indica
#       que el puntaje asociado al producto tiene incidencia en el puntaje asignado al Servicio otorgado al cliente.
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black",
tl.col="black", tl.srt=45,
diag=FALSE)
cor.test(complaint_reason_data_cor$avg_time_to_resolution, complaint_reason_data_cor$Prod_CSAT, method = "pearson", exact = FALSE)
cor.test(complaint_reason_data_cor$Prod_CSAT, complaint_reason_data_cor$Serv_CSAT, method = "pearson", exact = FALSE)
corrplot.mixed(M,
tl.pos = "lt",
diag = "l",
tl.col="black")
