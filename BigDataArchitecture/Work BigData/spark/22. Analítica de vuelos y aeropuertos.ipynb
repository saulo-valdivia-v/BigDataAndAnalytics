{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2. Analísis de datos de vuelos y aeropuertos con Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('vuelos').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio trataremos los datos de vuelos que tienen por origen o destino aeropuertos de EEUU, disponibles en las web https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data y https://openflights.org/data.html. Los datos de los vuelos están contenidos en el fichero departuredelays.csv incluyendo entre otros el identificador (código IATA) del aeropuerto origen y el destino, la distancia recorrida y el retraso en minutos. Además, en el archivo airport-codes-na.txt se tiene para cada código IATA, la siguiente información detallada del aeropuerto: Ciudad, Estado, País y Código IATA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga los datos del archivo departuredelays.csv en un Data Frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"file:///home/ubuntu/datos/sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelosDf = spark.read.format('csv') \\\n",
    "            .option('header','true') \\\n",
    "            .option('inferSchema','true') \\\n",
    "            .load(ruta + \"/departuredelays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|    6|     602|   ABE|        ATL|\n",
      "|1020600|   -8|     369|   ABE|        DTW|\n",
      "|1021245|   -2|     602|   ABE|        ATL|\n",
      "|1020605|   -4|     602|   ABE|        ATL|\n",
      "|1031245|   -4|     602|   ABE|        ATL|\n",
      "|1030605|    0|     602|   ABE|        ATL|\n",
      "|1041243|   10|     602|   ABE|        ATL|\n",
      "|1040605|   28|     602|   ABE|        ATL|\n",
      "|1051245|   88|     602|   ABE|        ATL|\n",
      "|1050605|    9|     602|   ABE|        ATL|\n",
      "|1061215|   -6|     602|   ABE|        ATL|\n",
      "|1061725|   69|     602|   ABE|        ATL|\n",
      "|1061230|    0|     369|   ABE|        DTW|\n",
      "|1060625|   -3|     602|   ABE|        ATL|\n",
      "|1070600|    0|     369|   ABE|        DTW|\n",
      "|1071725|    0|     602|   ABE|        ATL|\n",
      "|1071230|    0|     369|   ABE|        DTW|\n",
      "|1070625|    0|     602|   ABE|        ATL|\n",
      "|1071219|    0|     569|   ABE|        ORD|\n",
      "|1080600|    0|     369|   ABE|        DTW|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vuelosDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga los datos del archivo airport-codes-na.txt en un Data Frame.**\n",
    "Fijate en el archivo de entrada abriéndolo previamente: En este caso el separador no es el estándar ',' si no que es un tabulador '\\t'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeroDf = spark.read.format('csv') \\\n",
    "            .option('header','true') \\\n",
    "            .option('inferSchema','true') \\\n",
    "            .option('sep','\\t') \\\n",
    "            .load(ruta + \"/airport-codes-na.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------+----+\n",
      "|       City|State|Country|IATA|\n",
      "+-----------+-----+-------+----+\n",
      "| Abbotsford|   BC| Canada| YXX|\n",
      "|   Aberdeen|   SD|    USA| ABR|\n",
      "|    Abilene|   TX|    USA| ABI|\n",
      "|      Akron|   OH|    USA| CAK|\n",
      "|    Alamosa|   CO|    USA| ALS|\n",
      "|     Albany|   GA|    USA| ABY|\n",
      "|     Albany|   NY|    USA| ALB|\n",
      "|Albuquerque|   NM|    USA| ABQ|\n",
      "| Alexandria|   LA|    USA| AEX|\n",
      "|  Allentown|   PA|    USA| ABE|\n",
      "|   Alliance|   NE|    USA| AIA|\n",
      "|     Alpena|   MI|    USA| APN|\n",
      "|    Altoona|   PA|    USA| AOO|\n",
      "|   Amarillo|   TX|    USA| AMA|\n",
      "|Anahim Lake|   BC| Canada| YAA|\n",
      "|  Anchorage|   AK|    USA| ANC|\n",
      "|   Appleton|   WI|    USA| ATW|\n",
      "|     Arviat|  NWT| Canada| YEK|\n",
      "|  Asheville|   NC|    USA| AVL|\n",
      "|      Aspen|   CO|    USA| ASE|\n",
      "+-----------+-----+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aeroDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica de las operaciones de unión (join), agregación y filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula las 10 ciudades desde las que han despegado más vuelos**. Para ello, tendrás que: \n",
    "1. Hacer un Join entre ambos data frames cruzando el código IATA de origen (origin) con el código IATA del fata frame con información de los aeropuertos.\n",
    "2. Agrupar por ciudad y hacer el recuento de vuelos. Renombra la columna de recuento a 'NumVuelos' y la columna City a 'CiudadOrigen'\n",
    "3. Ordenar el resultado para mostrarlo por pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuelosOriJoin = vuelosDf.join(aeroDf,vuelosDf['origin']==aeroDf['IATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesVuelos = vuelosOriJoin.groupBy(vuelosOriJoin['City'].alias('CiudadOrigen')) \\\n",
    "        .agg(count(vuelosOriJoin['City']).alias('NumVuelos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "| CiudadOrigen|NumVuelos|\n",
      "+-------------+---------+\n",
      "|      Atlanta|    91484|\n",
      "|      Chicago|    84284|\n",
      "|       Dallas|    79754|\n",
      "|      Houston|    58101|\n",
      "|  Los Angeles|    54086|\n",
      "|       Denver|    53148|\n",
      "|     New York|    49030|\n",
      "|      Phoenix|    40155|\n",
      "|San Francisco|    39483|\n",
      "|    Las Vegas|    33107|\n",
      "+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ciudadesVuelos.orderBy(ciudadesVuelos['NumVuelos'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Además del número de vuelos 'NumVuelos', añade una columna con los retrasos acumulados por ciudad de origen 'RetrasoAcumulado'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasos = vuelosOriJoin.groupBy(vuelosOriJoin['City'].alias('CiudadOrigen')) \\\n",
    "        .agg(count(vuelosOriJoin['City']).alias('NumVuelos'),sum('delay').alias('RetrasoAcumulado'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra ahora solo las 10 ciudades con más retrasos acumulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----------------+\n",
      "| CiudadOrigen|NumVuelos|RetrasoAcumulado|\n",
      "+-------------+---------+----------------+\n",
      "|      Chicago|    84284|         1588183|\n",
      "|      Atlanta|    91484|         1151087|\n",
      "|       Denver|    53148|          899406|\n",
      "|       Dallas|    79754|          849448|\n",
      "|      Houston|    58101|          808480|\n",
      "|     New York|    49030|          691817|\n",
      "|  Los Angeles|    54086|          565490|\n",
      "|San Francisco|    39483|          501670|\n",
      "|       Newark|    27656|          452791|\n",
      "|      Orlando|    28313|          445070|\n",
      "+-------------+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ciudadesRetrasos.orderBy(ciudadesRetrasos['RetrasoAcumulado'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haz ahora el cálculo del retraso acumulado por ciudad pero filtrando el resultado para los aeropuertos cuyo país de origen sea 'USA' y el estado sea 'WA' (Washington)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasosWA = vuelosOriJoin.where(\"Country == 'USA' and State== 'WA'\") \\\n",
    "        .groupBy(vuelosOriJoin['City'].alias('CiudadOrigen')) \\\n",
    "        .agg(count(vuelosOriJoin['City']).alias('NumVuelos'),sum('delay').alias('RetrasoAcumulado'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------------+\n",
      "|CiudadOrigen|NumVuelos|RetrasoAcumulado|\n",
      "+------------+---------+----------------+\n",
      "|     Seattle|    23078|          159086|\n",
      "|     Spokane|     2044|           12404|\n",
      "|       Pasco|      623|             949|\n",
      "+------------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ciudadesRetrasosWA.orderBy(ciudadesRetrasosWA['RetrasoAcumulado'].desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica de la persistencia en disco de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos con el Data Frame con el número de vuelos y los retrasos calculados para todas las ciudades (sin filtrar).\n",
    "Antes hemos llamado a ese Data Frame ciudadesRetrasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------------+\n",
      "|CiudadOrigen|NumVuelos|RetrasoAcumulado|\n",
      "+------------+---------+----------------+\n",
      "|   Fairbanks|      812|           -2403|\n",
      "|       Tyler|      661|            2358|\n",
      "|  Charleston|     3597|           39197|\n",
      "|  Harrisburg|     1054|           13096|\n",
      "|       Pasco|      623|             949|\n",
      "+------------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ciudadesRetrasos.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persiste en formato CSV en \"file:///home/ubuntu/datos/salida/ciudadesRetrasosCSV\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el uso de las rutas en los ejercicios de persistencia, puedes usar una variable con la ruta base como la siguiente. Puedes usarla para componer la ruta de salida en cada caso. Ejemplo: rutaSalida + \"/ciudadesRetrasosCSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaSalida = \"file:///home/ubuntu/datos/salida\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasos.write.format(\"csv\") \\\n",
    "    .save(rutaSalida + \"/ciudadesRetrasosCSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprueba que los datos se han escrito en el directorio y fijate en el número de archivos que se han generado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Se ha generado más de un archivo? ¿Por que?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** Sí. Porque el DF ciudadesRetrasos está particionado en la memoria del clúster Spark y se generan tantos archivos como particiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persiste de nuevo el DF en la misma ruta sobrescribiendo los datos y almacenando la cabecera**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasos.write.format(\"csv\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(rutaSalida + \"/ciudadesRetrasosCSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo has hecho bien, puedes comprobar que todos los archivos generados en la ruta incluyen la cabecera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga ahora los datos guardados en un nuevo data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrasosDF = spark.read.format(\"csv\"). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(rutaSalida + \"/ciudadesRetrasosCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----------------+\n",
      "| CiudadOrigen|NumVuelos|RetrasoAcumulado|\n",
      "+-------------+---------+----------------+\n",
      "|    Nashville|    13733|          212243|\n",
      "|        Flint|      981|            9799|\n",
      "|Oklahoma City|     4935|           58120|\n",
      "|    San Diego|    18005|          197190|\n",
      "|San Francisco|    39483|          501670|\n",
      "+-------------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrasosDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz un recuento de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrasosDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora prueba a guardar los datos de este nuevo Dataframe en el mismo directorio que los que ya teniamos, como si fuesen nuevos datos (filas) que queremos añadir a los que ya existian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrasosDF.write.format(\"csv\") \\\n",
    "    .option(\"header\",\"True\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(rutaSalida + \"/ciudadesRetrasosCSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga ahora los datos guardados en disco en nuevo DF y haz un recuento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrasosDFmas = spark.read.format(\"csv\"). \\\n",
    "    option(\"header\", \"true\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(rutaSalida + \"/ciudadesRetrasosCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrasosDFmas.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos ahora al DF ciudadesRetrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------------+\n",
      "|CiudadOrigen|NumVuelos|RetrasoAcumulado|\n",
      "+------------+---------+----------------+\n",
      "|   Fairbanks|      812|           -2403|\n",
      "|       Tyler|      661|            2358|\n",
      "|  Charleston|     3597|           39197|\n",
      "|  Harrisburg|     1054|           13096|\n",
      "|       Pasco|      623|             949|\n",
      "+------------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ciudadesRetrasos.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el número de particiones que tiene actualmente, puedes hacer lo siguiente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciudadesRetrasos.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparticiona ahora el Data Frame para conseguir solo 3 particiones y crea un nuevo DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasosRep3 = ciudadesRetrasos.repartition(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba ahora el número de particiones del nuevo DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciudadesRetrasosRep3.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda ahora ciudadesRetrasosRep3 a disco en formato CSV, con cabecera y con sobrescritura, usando la misma ruta de antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasosRep3.write.format(\"csv\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(rutaSalida + \"/ciudadesRetrasosCSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba cuantos archivos se han generado ahora con el siguiente comando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-51ea5b23-f94d-4f72-91a3-ba4d78aa0216-c000.csv\r\n",
      "part-00001-51ea5b23-f94d-4f72-91a3-ba4d78aa0216-c000.csv\r\n",
      "part-00002-51ea5b23-f94d-4f72-91a3-ba4d78aa0216-c000.csv\r\n",
      "_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "ls /home/ubuntu/datos/salida/ciudadesRetrasosCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta** : 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora prueba a escribir el mismo resultado en formato Parquet en la ruta** file:///home/ubuntu/datos/salida/ciudadesRetrasosParquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesRetrasosRep3.write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(rutaSalida + \"/ciudadesRetrasosParquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abre el directorio de salida y comprueba el contenido de los archivos. Responde a las siguientes preguntas** \n",
    "1. ¿puedes ver su contenido desde el explorador, notepad, comando cat....? \n",
    "2. ¿Están comprimidos? En caso afirmativo, indica la compresión usada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**: El formato Parquet no es texto plano, por lo que no se puede visualizar con un editor de textos o con cualquier herramienta o comando que no sepa leer este formato. Por defecto, la compresión usada en Spark para el formato Parquet es Snappy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga ahora desde disco los datos en Parquet a un nuevo DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudadesFromParquet = spark.read.format('parquet') \\\n",
    "    .load(rutaSalida + \"/ciudadesRetrasosParquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------------+\n",
      "|CiudadOrigen|NumVuelos|RetrasoAcumulado|\n",
      "+------------+---------+----------------+\n",
      "|   Fairbanks|      812|           -2403|\n",
      "|  Charleston|     3597|           39197|\n",
      "| Springfield|     1641|           25896|\n",
      "|   Allentown|      448|            5113|\n",
      "|    Valdosta|      253|            2598|\n",
      "+------------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ciudadesFromParquet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cierra ahora la sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
