{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init(os.environ['SPARK_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bigdata/apps/spark-3.0.1\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SPARK_HOME'])\n",
    "#import pyspark\n",
    "#import pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de un contexto de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()\n",
    "#sc.SparkContext()\n",
    "\n",
    "#sc = SparkContext('local[2]', 'TestingRDDs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empezando con RDDs\n",
    "\n",
    "### Creando un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualizar una lista de RDD\n",
    "rdd = sc.parallelize([1, 8, 1, 1, 2, 2, 2, 3, 3, 4])\n",
    "print (rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glom: devuelve un nuevo RDD juntando los elementos \n",
    "#de cada partición en una lista\n",
    "print (rdd.glom().collect())\n",
    "print (\"Numero de particiones: \",rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar una lista de RDD\n",
    "rdd2 = sc.parallelize([1, 8, 1, 1, 2, 2, 2, 3, 3, 4],12)\n",
    "print (rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (rdd2.glom().collect())\n",
    "print (\"Numero de particiones: \",rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones de acción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de elementos del RDD\n",
    "print (rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primer elemento\n",
    "print (rdd.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diccionario con la frecuencia de cada elemento\n",
    "print (rdd.countByValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar los 4 primeros elementos\n",
    "print (rdd.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular la media\n",
    "print (rdd.mean())\n",
    "\n",
    "#Calcular la varianza\n",
    "print (rdd.variance())\n",
    "\n",
    "#Calcular la desviación típica\n",
    "print (rdd.stdev())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones de transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando funcion map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicar por 2 todos los elementos del RDD y almacenar el resultado en un nuevo RDD\n",
    "myRDD2 = rdd.map(lambda x: x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obten el tipo de myRDD\n",
    "type(myRDD2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando funcion flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de frases de un texto\n",
    "texto = [\"Ejemplo flatMap con Spark\",\"palabra\", \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus iaculis magna eget turpis maximus cursus. Etiam at facilisis massa. Donec in neque faucibus, aliquam velit nec, aliquam felis. Duis sed iaculis justo. Vestibulum eget metus sed mauris imperdiet tempor. Ut lorem nulla, luctus vel dignissim eget, volutpat vel mauris. Sed sit amet pellentesque nibh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en RDD\n",
    "textoRDD = sc.parallelize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textoRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palRDD = textoRDD.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar un diccionario\n",
    "a = sc.parallelize(['a','b','c','a','a'])\n",
    "b = sc.parallelize([1,2,3,4,5])\n",
    "rdd_kv = a.zip(b)\n",
    "print (rdd_kv.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acceder a las claves de un diccionario\n",
    "print (rdd_kv.keys().collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acceder a los valores de un diccionario\n",
    "print (rdd_kv.values().collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiplicar por dos los valores de un diccionario\n",
    "print (rdd_kv.mapValues(lambda value : value*3).collect())\n",
    "\n",
    "#Sumar por llave los valores de un diccionario\n",
    "print (rdd_kv.reduceByKey(lambda valueK1,valueK2: valueK1 + valueK2).collect())\n",
    "\n",
    "print(rdd_kv.mapValues(lambda value : value*3).reduceByKey(lambda valueK1,valueK2: valueK1 + valueK2).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenar los valores de un diccionario\n",
    "print (rdd_kv.sortByKey(False).collect())\n",
    "print (rdd_kv.sortByKey(True).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación a partir de diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicRDD = sc.parallelize([(\"autor\",\"Fernando de Rojas\"), (\"titulo\",\"La celestina\"),(\"anio\",1499)]) # Importantes los corchetes []\n",
    "print(dicRDD.collect()) # Visualizar la colección RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir de dos colecciones\n",
    "a = sc.parallelize(['a','b','c','a'])\n",
    "b = sc.parallelize([1,2,3,4])\n",
    "rdd_kv = a.zip(b)\n",
    "print (rdd_kv.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenando RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenar los 5 primeros elementos del RDD\n",
    "print (rdd.takeOrdered(5))\n",
    "\n",
    "#Ordenar inversamente los 5 primeros elementos del RDD\n",
    "print(rdd.takeOrdered(5, lambda x: -x))\n",
    "\n",
    "#Ordena todo el RDD y devuelve otro RDD\n",
    "rdd_aux = rdd.sortBy(lambda x: x)\n",
    "print(rdd_aux.collect())\n",
    "\n",
    "#Ordena todo el RDD y devuelve otro RDD\n",
    "rdd_aux = rdd.sortBy(lambda x: x, ascending=True)\n",
    "print(rdd_aux.collect())\n",
    "\n",
    "#Ordena inversamente todo el RDD y devuelve otro RDD\n",
    "rdd_aux2 = rdd.sortBy(lambda x:-x)\n",
    "print(rdd_aux2.collect())\n",
    "\n",
    "#Ordena todo el RDD y devuelve otro RDD\n",
    "rdd_aux = rdd.sortBy(lambda x: x, ascending=False)\n",
    "print(rdd_aux.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado de datos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_num = sc.parallelize([1, 1, 1, 5, 2, 2, 2, 3, 3, 4])\n",
    "rdd_num_filtered = rdd_num.filter(lambda num : num <= 2)\n",
    "print (rdd_num_filtered.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado de datos en textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_text = sc.parallelize(['Delete entry lines', '', '', '', '','No more'])\n",
    "rdd_aux = rdd_text.filter(lambda texto : texto != '')\n",
    "print (rdd_aux.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple key value examples\n",
    "dataset1 = sc.parallelize(\n",
    "    [('key1', (6, 77777)), ('key2', 4), ('key7', 5), ('key10', 6)])\n",
    "dataset2 = sc.parallelize(\n",
    "    [('key1', 2), ('key3', 7), ('key8', 5), ('key10', 1)])\n",
    "\n",
    "dataset1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.join(dataset2).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.leftOuterJoin(dataset2).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.rightOuterJoin(dataset2).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.fullOuterJoin(dataset2).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection  and union\n",
    "set1 = sc.parallelize([1, 2, 4, 3, 4, 5 ,6])\n",
    "set2 = sc.parallelize([2, 4, 6, 8, 10])\n",
    "set1.intersection(set2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1.union(set2).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un RDD que multiplique por 2 sus valores y sumar los resultados\n",
    "from operator import add\n",
    "rdd = sc.parallelize([1, 1, 1, 1, 2, 2, 2, 3, 3, 4])\n",
    "rdd2 = rdd.map(lambda x: x*2)\n",
    "tSum = rdd2.reduce(lambda x,y: x+y)\n",
    "print (tSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un diccionario con elementos (x,1) y sumar las apariciones por elemento\n",
    "rdd_text = sc.parallelize(['blue','blue','red', 'red', 'blue', 'green', 'green','yellow'])\n",
    "rdd_aux = rdd_text.map(lambda x: (x,1))\n",
    "rdd_result = rdd_aux.reduceByKey(lambda x,y: x+y)\n",
    "print (rdd_result.collect())\n",
    "\n",
    "#rdd_text.map(lambda x: (x,1)).rdd_aux.reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = not_empty_lines.flatMap(lambda x: x.split(' '))\n",
    "word_map = words.map(lambda x: (x, 1))\n",
    "reduce = word_map.reduceByKey(lambda c, b: c + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con ficheros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de ficheros externos en RDD\n",
    "rdd_file = sc.textFile(\"file:///home/ubuntu/bigdata/examples/books/Frankenstein.txt\")\n",
    "#rdd_file = sc.textFile(\"file:///home/ubuntu/bigdata/examples/books/Frankenstein.txt\",8)\n",
    "print (rdd_file.getNumPartitions())\n",
    "print (rdd_file.count())\n",
    "print (rdd_file.take(10))\n",
    "print (rdd_file.first())\n",
    "#Escritura de RDD en un directorio\n",
    "#rdd_file.saveAsTextFile(\"file:///home/ubuntu/bigdata/examples/books/result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rdd_quijote = sc.textFile(\"/books/Quijote.txt\")\n",
    "print(rdd_quijote.take(1))\n",
    "rdd_palabras_linea = rdd_quijote.flatMap(lambda linea : linea.split(' '))#comentario\n",
    "rdd_clave_valor = rdd_palabras_linea.map(lambda palabra: (palabra,1))\n",
    "rdd_result = rdd_clave_valor.reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "output = rdd_result.takeOrdered(10, key = lambda clave_valor: -clave_valor[1])\n",
    "#output = rdd_result.takeOrdered(10)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
