{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistencia\n",
    "\n",
    "## Problema al usar un RDD varias veces:\n",
    "* Spark recomputa el RDD y sus dependencias cada vez que se ejecuta una acción\n",
    "* Muy costoso (especialmente en problemas iterativos)\n",
    "\n",
    "\n",
    "## Solución:\n",
    "* Conservar el RDD en memoria y/o disco\n",
    "* Métodos cache() o persist() y unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Niveles de persistencia (definidos en pyspark.StorageLevel)\n",
    "\n",
    "| Nivel \t| Espacio \t| CPU \t| Memoria/Disco \t| Descripción \t|\n",
    "|---------------------\t|---------\t|-------\t|---------------\t|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| MEMORY_ONLY \t| Alto \t| Bajo \t| Memoria \t| Guarda el RDD como un objeto Java no serializado en la JVM. Si el RDD no cabe en memoria, algunas particiones no se cachearán y serán recomputadas “al vuelo” cada vez que se necesiten. Nivel por defecto en Java y Scala. \t|\n",
    "| MEMORY_ONLY_SER \t| Bajo \t| Alto \t| Memoria \t| Guarda el RDD como un objeto Java serializado (un byte array por partición). Nivel por defecto en Python, usando pickle. \t|\n",
    "| MEMORY_AND_DISK \t| Alto \t| Medio \t| Ambos \t| Guarda el RDD como un objeto Java no serializado en la JVM. Si el RDD no cabe en memoria, las particiones que no quepan se guardan en disco y se leen del mismo cada vez que se necesiten \t|\n",
    "| MEMORY_AND_DISK_SER \t| Bajo \t| Alto \t| Ambos \t| Similar a MEMORY_AND_DISK pero usando objetos serializados. \t|\n",
    "| DISK_ONLY \t| Bajo \t| Alto \t| Disco \t| Guarda las particiones del RDD solo en disco. \t|\n",
    "| OFF_HEAP \t| Bajo \t| Alto \t| Memoria \t| Guarda el RDD serializado usando memoria off-heap (fuera del heap de la JVM) lo que puede reducir el overhead del recolector de basura \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel de persistencia\n",
    "\n",
    "* En Scala y Java, el nivel por defecto es MEMORY_ONLY\n",
    "\n",
    "* En Python, los datos siempre se serializan (por defecto como objetos pickled)\n",
    "\n",
    "    * Los niveles MEMORY_ONLY, MEMORY_AND_DISK son equivalentes a MEMORY_ONLY_SER, MEMORY_AND_DISK_SER\n",
    "    * Es posible especificar serialización marshal al crear el SparkContext\n",
    "    \n",
    "        sc = SparkContext(master=\"local\", appName=\"Mi app\", serializer=pyspark.MarshalSerializer())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestión de la cache\n",
    "* Algoritmo para gestionar la cache\n",
    "    * Para niveles solo memoria, los RDDs viejos se eliminan y se recalculan\n",
    "    * Para niveles memoria y disco, las particiones que no caben se escriben a disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkContext Creado\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init(os.environ['SPARK_HOME'])\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "app_name = \"Test1\"\n",
    "master = \"local[*]\"\n",
    "spark = (SparkSession.builder\n",
    "    .master(master)\n",
    "    .appName(app_name)\n",
    "    .getOrCreate() )\n",
    "    \n",
    "sc = spark.sparkContext\n",
    "print(\"SparkContext Creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1000), 10)\n",
    "\n",
    "print(rdd.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Nivel de persistencia de rdd: Disk Memory Serialized 2x Replicated \n"
     ]
    }
   ],
   "source": [
    "rdd.persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "\n",
    "print(rdd.is_cached)\n",
    "\n",
    "print(\"Nivel de persistencia de rdd: {0} \".format(rdd.getStorageLevel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "rdd2 = rdd.map(lambda x: x*x)\n",
    "print(rdd2.is_cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Nivel de persistencia de rdd2: Memory Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "rdd2.cache() # Nivel por defecto\n",
    "print(rdd2.is_cached)\n",
    "print(\"Nivel de persistencia de rdd2: {0}\".format(rdd2.getStorageLevel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "rdd2.unpersist() # Sacamos rdd2 de la cache\n",
    "print(rdd2.is_cached)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
